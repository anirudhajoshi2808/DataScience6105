{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">INFO 6105 Data Sci Engineering Methods and Tools, Week 5 Lecture 2</div>\n",
    "<div style=\"text-align: right\">Dino Konstantopoulos, 9 February 2023, with material by Chris Fonnesbeck and Cyrille Rossant</div>\n",
    "<div style=\"text-align: right\"><i>please browse all URLs in this notebook</i></div>\n",
    "\n",
    "So we learned **probability theory**. Basically, *if you can count* by building your random-variable sets and the predicates you want to apply on the datasets with python, you do not need to know the math behind probability theory (but knowing some of the math is helpful). \n",
    "\n",
    "We also did an introduction to **Bayes' formula**, which allows you to invert the precondition and the postcondition on a conditional probability to make probabilities easier to evaluate. That is very useful for data science interviews that involve probability questions. We looked at an example counting M&Ms.\n",
    "\n",
    "But Bayes' formula will open up a new universe of statistics for us, which we'll get into. For now, let's learn about *classical statistics*. What was invented in the 1800s. All in two notebooks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"divCheckbox\" style=\"display: none;\">\n",
    "\"20102020\"[::-1]\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Method Of Moments (MOM) \n",
    "\n",
    "We'll illustrate the **Method of Moments** (MOM) with ***an example***. If you fall asleep in your statistics class, it's the ***fault of the professor!***\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src =ipynb.images/asleep.jpg width = 400 />\n",
    "\n",
    "A professor should give you ***interesting problems*** to keep you awake. Then you’ll have an appreciation for how statistics helps us to understand the world. There are many **interesting phenomena** in the world, and we use data science as a tool for exploring them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-machine-assisted data science\n",
    "We already know that random-looking datasets actually can have very normal-looking pdfs. So, given a normal-looking pdf, we can generate a lot of different random-lloking datasets.\n",
    "\n",
    ">**Goal**: Match the histogram of the data to a known pdf (figure out the parameters of that pdf if the pdf is parametric), and then use that pdf to generate data and do prdictions, rather than using the original dataset, because it's a lot easier than interpolation.\n",
    "\n",
    "So, what Neanderthal data scientists did is to try to match the histogram of datasets to well-known theoretical profiles, and then they can use the theoretical profile (gaussian, gamma, etc.) to simulate data! \n",
    "\n",
    "Pretty clever, huh?\n",
    "\n",
    "Now, with computers, ***we can do the same thing***, i.e. find the best approximation to our empirical histogram and then use libraries like `SciPy` to build simulations of (the process underlying) our data. So we don't need the math, as much as the Neanderthals did. Also, we can do additional things with computers using bayesian statistics, which we'll look into next week.\n",
    "\n",
    "> **IMPORTANT**: Why do we want to produce data that may *look* different and yet follows the same histogram? Because we theorize that by capturing the histogram, we are modelling the *process* that produced the data, which is *what we're really after*. Plus real-world data has noise, and we don't like noise! Matching the random-looking data with a well-known pdfs has a *smoothing effect*. That is what **data science** is all about.\n",
    "\n",
    "To understand Neanderthal data scientists better, let's do some labs and try to leverage the parametrized distributions we just learned as potential models to datasets we observe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab \\#1: Nashville Precipitation\n",
    "\n",
    "The dataset `nashville_precip.txt` contains NOAA precipitation data for the city of Nashville, Tennessee, measured since 1871. It is a classical dataset, like the iris dataset. Download it from canvas and put it in the right folder (you know..). The gamma distribution is a good fit to aggregated rainfall data, and will be our candidate distribution in this case. We'll use the gamma distribution model for Nashville precipitation to demonstrate the [Method of Moments](https://en.wikipedia.org/wiki/Method_of_moments_(statistics)) (MOM).\n",
    "\n",
    "The other method is Maximum Likelihood Estimation, which in some cases is intractable without computers. The method-of-moments estimators however can be computed much more quickly and easily. Due to this easy computability, method-of-moments estimates may be used as the first approximation to the solutions of the likelihood equations, and successive improved approximations may then be found by the Newton–Raphson method. \n",
    "\n",
    "Let's peek at our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>2.76</td>\n",
       "      <td>4.58</td>\n",
       "      <td>5.01</td>\n",
       "      <td>4.13</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>2.32</td>\n",
       "      <td>2.11</td>\n",
       "      <td>3.14</td>\n",
       "      <td>5.91</td>\n",
       "      <td>3.09</td>\n",
       "      <td>5.17</td>\n",
       "      <td>6.10</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>2.96</td>\n",
       "      <td>7.14</td>\n",
       "      <td>4.11</td>\n",
       "      <td>3.59</td>\n",
       "      <td>6.31</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.63</td>\n",
       "      <td>2.36</td>\n",
       "      <td>1.81</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.36</td>\n",
       "      <td>5.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>5.22</td>\n",
       "      <td>9.23</td>\n",
       "      <td>5.36</td>\n",
       "      <td>11.84</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.87</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.63</td>\n",
       "      <td>6.12</td>\n",
       "      <td>4.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>6.15</td>\n",
       "      <td>3.06</td>\n",
       "      <td>8.14</td>\n",
       "      <td>4.22</td>\n",
       "      <td>1.73</td>\n",
       "      <td>5.63</td>\n",
       "      <td>8.12</td>\n",
       "      <td>1.60</td>\n",
       "      <td>3.79</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.46</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Jan   Feb   Mar    Apr   May   Jun   Jul   Aug   Sep   Oct   Nov   Dec\n",
       "Year                                                                         \n",
       "1871  2.76  4.58  5.01   4.13  3.30  2.98  1.58  2.36  0.95  1.31  2.13  1.65\n",
       "1872  2.32  2.11  3.14   5.91  3.09  5.17  6.10  1.65  4.50  1.58  2.25  2.38\n",
       "1873  2.96  7.14  4.11   3.59  6.31  4.20  4.63  2.36  1.81  4.28  4.36  5.94\n",
       "1874  5.22  9.23  5.36  11.84  1.49  2.87  2.65  3.52  3.12  2.63  6.12  4.19\n",
       "1875  6.15  3.06  8.14   4.22  1.73  5.63  8.12  1.60  3.79  1.25  5.46  4.30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precip = pd.read_table(\"data/nashville_precip.txt\", index_col=0, na_values='NA', delim_whitespace=True)\n",
    "precip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>3.32</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.99</td>\n",
       "      <td>4.95</td>\n",
       "      <td>6.20</td>\n",
       "      <td>3.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>4.76</td>\n",
       "      <td>2.53</td>\n",
       "      <td>5.56</td>\n",
       "      <td>7.20</td>\n",
       "      <td>5.54</td>\n",
       "      <td>2.21</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.88</td>\n",
       "      <td>5.03</td>\n",
       "      <td>1.75</td>\n",
       "      <td>6.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>4.59</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.92</td>\n",
       "      <td>4.13</td>\n",
       "      <td>8.45</td>\n",
       "      <td>4.53</td>\n",
       "      <td>6.03</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.08</td>\n",
       "      <td>6.49</td>\n",
       "      <td>0.67</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>4.13</td>\n",
       "      <td>2.77</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.48</td>\n",
       "      <td>16.43</td>\n",
       "      <td>4.96</td>\n",
       "      <td>5.86</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.49</td>\n",
       "      <td>5.41</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2.31</td>\n",
       "      <td>5.54</td>\n",
       "      <td>4.59</td>\n",
       "      <td>7.51</td>\n",
       "      <td>4.38</td>\n",
       "      <td>5.04</td>\n",
       "      <td>3.46</td>\n",
       "      <td>1.78</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>6.15</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Jan   Feb   Mar   Apr    May   Jun   Jul   Aug    Sep   Oct   Nov   Dec\n",
       "Year                                                                          \n",
       "2007  3.32  1.84  2.26  2.75   3.30  2.37  1.47  1.38   1.99  4.95  6.20  3.83\n",
       "2008  4.76  2.53  5.56  7.20   5.54  2.21  4.32  1.67   0.88  5.03  1.75  6.72\n",
       "2009  4.59  2.85  2.92  4.13   8.45  4.53  6.03  2.14  11.08  6.49  0.67  3.99\n",
       "2010  4.13  2.77  3.52  3.48  16.43  4.96  5.86  6.99   1.17  2.49  5.41  1.87\n",
       "2011  2.31  5.54  4.59  7.51   4.38  5.04  3.46  1.78   6.20  0.93  6.15  4.25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precip.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the year 1871, in the month of January, Nashville saw 2.76 inches of rainfall.\n",
    "\n",
    "### 1. Data Exploration: The Histogram\n",
    "\n",
    "Let's do some data exploration with the ***histogram*** of precipitations, month by month. The histogram of a specific mootn tells us what's the most frequent number of inches of rain from 1871 onward.\n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"ipynb.images/rainfall.jpeg\" width=400 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "_ = precip.hist(sharex=True, sharey=True, grid=False)\n",
    "plt.tight_layout()\n",
    "```\n",
    "Then:\n",
    "```\n",
    "precip.Jan.hist()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is recognizing what sort of distribution to fit our data to. A couple of observations:\n",
    "\n",
    "1. The data is *skewed*, with a longer tail to the right than to the left\n",
    "2. The data is positive-valued, since they are measuring rainfall\n",
    "3. The data is continuous\n",
    "\n",
    "Even just by ***eyeballing*** the theoretical pdfs we introduced (normal, Poisson, etc.) , ***even if you did not know what the Gamma distribution is usually used for***, a good option appears to be the **gamma distribution**: The curves look like ***Gaussians with long tails***. That's a Gamma!\n",
    "\n",
    "<br />\n",
    "<div style=\"font-size: 120%;\">  \n",
    "$$x \\sim \\text{Gamma}(\\alpha, \\beta) = \\frac{x^{\\alpha-1}e^{- x/\\beta}}{\\beta^{\\alpha}\\Gamma(\\alpha)}$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Cleansing \n",
    "\n",
    "***Wait***, there's something ***wrong*** with our data.. if you open it in a text editor, you will find a value of **NA** for October of 1963 (take a look). \n",
    "\n",
    "So we have to do some **data cleansing** first. That step is called **exploratory data cleansing** (EDA). *Always* do that, first.\n",
    "\n",
    "Given what we are trying to do, it is ***sensible*** to fill in the missing value with the average of the available values (another option would have been the average of the months of September and November 1963). Filling in with 0 would be a *bad idea*.\n",
    "\n",
    "```\n",
    "precip.fillna(value={'Oct': precip.Oct.mean()}, inplace=True)\n",
    "precip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Method of Moments\n",
    "\n",
    "The **method of moments** simply assigns the **empirical** (coming from the data) **mean** and **variance** to their **theoretical counterparts** (coming from the *model*, in this case the Gamma!), so that we can ***solve for the parameters*** of the Gamma!\n",
    "\n",
    "So, for the gamma distribution, the mean and variance turn out to be (analytically derived):\n",
    "\n",
    "<br />\n",
    "<div style=\"font-size: 120%;\">  \n",
    "$$ \\hat{\\mu} = \\bar{X} = \\alpha \\beta $$\n",
    "$$ \\hat{\\sigma}^2 = S^2 = \\alpha \\beta^2 $$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if we solve for these parameters, we can use a gamma distribution to describe our data, with parameters:\n",
    "\n",
    "<br />\n",
    "<div style=\"font-size: 120%;\">  \n",
    "$$ \\alpha = \\frac{\\bar{X}^2}{S^2}, \\, \\beta = \\frac{S^2}{\\bar{X}} $$\n",
    "</div>\n",
    "\n",
    "($\\bar{X}$ is the mean, while $S^2$ is the variance of each column of the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate the sample ***moments of interest***: the **means** and **variances** *month by month*, using good ol' `pandas`:\n",
    "```\n",
    "precip_mean = precip.mean()\n",
    "precip_mean\n",
    "```\n",
    "\n",
    "```\n",
    "precip_var = precip.var()\n",
    "precip_var\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use these moments to estimate $\\alpha$ and $\\beta$ for each month:\n",
    "```python\n",
    "alpha_mom = ...\n",
    "beta_mom = ...\n",
    "alpha_mom, beta_mom\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:none;\">\n",
    "alpha_mom = precip_mean ** 2 / precip_var\n",
    "beta_mom = precip_var / precip_mean\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, use the `gamma.pdf` function in `scipy.stats.distributions` to plot the distributions implied by the calculated alphas and betas. \n",
    "\n",
    "For example, here is `January` (and note that scipy's gamma is the *gamma distribution*, not the $\\Gamma$ function that interpolates $n!$ to real numbers, even though the $\\Gamma$ function figures in the denominator of the gamma distribution):\n",
    "```\n",
    "from scipy.stats.distributions import gamma\n",
    "\n",
    "precip.Jan.hist(normed=True, bins=20)\n",
    "plt.plot(np.linspace(0, 10), gamma.pdf(np.linspace(0, 10), alpha_mom[0], beta_mom[0]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".**Note**: If this API call does not work, it may work with named arguments, like this:\n",
    "```\n",
    "plt.plot(np.linspace(0, 10), gamma.pdf(np.linspace(0, 10), a = alpha_mom[0], scale = beta_mom[0]))\n",
    "```\n",
    "\n",
    "Not bad for january :-) Looping over all months now, create a grid of plots for the distribution of rainfall, using the gamma distribution. Here is how you can create a grid of plots:\n",
    "\n",
    "```python\n",
    "axs = precip.hist(normed=True, figsize=(12, 8), sharex=True, sharey=True, bins=15, grid=True)\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    \n",
    "    # Get month\n",
    "    m = ax.get_title()\n",
    "    \n",
    "    # Plot fitted distribution\n",
    "    x = np.linspace(*ax.get_xlim())\n",
    "    ax.plot(x, gamma.pdf(x, alpha_mom[m], beta_mom[m]))\n",
    "    \n",
    "    # Annotate with parameter estimates\n",
    "    label = 'alpha = {0:.2f}\\nbeta = {1:.2f}'.format(alpha_mom[m], beta_mom[m])\n",
    "    ax.annotate(label, xy=(10, 0.2))\n",
    "    \n",
    "plt.tight_layout()\n",
    "```\n",
    "\n",
    "You may have to change `normed` attribute in the code to `density`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:none;\">\n",
    "axs = precip.hist(normed=True, figsize=(12, 8), sharex=True, sharey=True, bins=15, grid=True)\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    \n",
    "    # Get month\n",
    "    m = ax.get_title()\n",
    "    \n",
    "    # Plot fitted distribution\n",
    "    x = np.linspace(*ax.get_xlim())\n",
    "    ax.plot(x, gamma.pdf(x, alpha_mom[m], beta_mom[m]))\n",
    "    \n",
    "    # Annotate with parameter estimates\n",
    "    label = 'alpha = {0:.2f}\\nbeta = {1:.2f}'.format(alpha_mom[m], beta_mom[m])\n",
    "    ax.annotate(label, xy=(10, 0.2))\n",
    "    \n",
    "plt.tight_layout()\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job, that was **data science**! You built a model from precipitation data, and now when somebody asks you to about weather for a certain month, you can give a good (historical) prediction.\n",
    "<left>\n",
    "<img src=\"ipynb.images/good-job-bear.png\" width=200 />\n",
    "</left>\n",
    "\n",
    "### 4. Conclusion\n",
    "\n",
    "In math, a **moment** is a specific quantitative measure of the ***shape of a set of points***. \n",
    "\n",
    "The *zeroth* moment is the total mass, the *first* moment is the center of mass, the *second* moment is rotational inertia. Oops.. this is not mechanics 101, it's statistics 101...\n",
    "\n",
    "So, the *zeroth* moment is total probability, *first* moment is the [mean](https://en.wikipedia.org/wiki/Mean), *second* moment is the [variance](https://en.wikipedia.org/wiki/Variance), *third* moment is the [skewness](https://en.wikipedia.org/wiki/Skewness), *fourth* moment is the [kurtosis](https://en.wikipedia.org/wiki/Kurtosis). And you can keep on going...\n",
    "\n",
    "For a distribution of mass or probability on a bounded interval, the collection of all the moments (of all orders, from 0 to $\\infty$) ***uniquely determines the distribution***. This is related to [Taylor's approximation theorem](https://en.wikipedia.org/wiki/Taylor%27s_theorem).\n",
    "\n",
    "Minimum number of moments we need in the **Method of Moments** equal the ***number of the parameters in the estimator***! For each moment, we equate the moment of the ***model + parameters*** to the moment of the dataset. That gives us ***one*** equation for the parameters. We will need as many equations (thus moments) as there are parameters!\n",
    "\n",
    "The method of Moments is ***easy-peasy***, as long as we have analytic formulas for the moments for the model distribution (which we usually do, *that is why* they are **models**). \n",
    "\n",
    "But they're usually *not* the most efficient estimators.\n",
    "\n",
    "Next, we look at Maximum Likelihood Estimation (MLE), which is a little bit harder to understand because we need to learn some more math...\n",
    ">**Note**: That math will be extremely useful for us though, because it's the basis of Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "Finish computing this notebook.\n",
    "\n",
    "Find a simple dataset with a **one-humped** histogram and model it by matching with the pdfs we learned today. Find the most likely parameters for your pdf using MOM. Use the model to do a prediction.\n",
    "\n",
    "***You will work in teams of 2***. Your TAs will assign you in working teams.\n",
    "\n",
    "Please find an ***original dataset***. Don't use a boring dataset that everyone can easily google for :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
